# -*- coding: utf-8 -*-
"""Movie_Recommender_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cb_0lRFDr63OPr7zv4MM0VcvjOm8waUR

# Movie Recommendation System

This notebook demonstrates the process of building a content-based movie recommendation system using the TMDB 5000 Movie Dataset. The system recommends movies based on the similarity of their content, including genres, keywords, cast, and crew.

## Table of Contents

1.  [Loading the Data](#loading-the-data)
2.  [Merging the DataFrames](#merging-the-dataframes)
3.  [Data Inspection](#data-inspection)
4.  [Filtering Relevant Columns](#filtering-relevant-columns)
5.  [Handling Missing Values](#handling-missing-values)
6.  [Checking for Duplicates](#checking-for-duplicates)
7.  [Extracting Information from JSON Strings](#extracting-information-from-json-strings)
8.  [Cleaning and Combining Tags](#cleaning-and-combining-tags)
9.  [Creating a New DataFrame with Essential Information](#creating-a-new-dataframe-with-essential-information)
10. [Lowercasing and Joining Tags](#lowercasing-and-joining-tags)
11. [Text Stemming](#text-stemming)
12. [Vectorizing Text Data](#vectorizing-text-data)
13. [Calculating Cosine Similarity](#calculating-cosine-similarity)
14. [Creating a Recommendation Function](#creating-a-recommendation-function)
15. [Testing the Recommendation Function](#testing-the-recommendation-function)

## 1. Loading the Data

We begin by loading the two datasets: `tmdb_5000_movies.csv` and `tmdb_5000_credits.csv` into pandas DataFrames. These datasets contain information about movies and their corresponding cast and crew.
"""

import pandas as pd
import numpy as np
import ast
from google.colab import drive

movies = pd.read_csv('tmdb_5000_movies.csv')
credits = pd.read_csv('tmdb_5000_credits.csv')

"""## 2. Merging the DataFrames

To combine the movie information with the cast and crew details, we merge the `movies` and `credits` DataFrames based on the 'title' column.
"""

movies = movies.merge(credits, on='title')

"""## 3. Data Inspection

Before proceeding, we inspect the merged DataFrame to understand its structure and identify any potential issues. We check the shape of the DataFrame and examine the distribution of the 'status' column.
"""

print("Shape of the merged DataFrame:", movies.shape)
print("\nValue counts for 'status' column:")
print(movies['status'].value_counts())
print("\nInformation about the DataFrame:")
print(movies.info())

"""## 4. Filtering Relevant Columns

For our content-based recommendation system, we only need a subset of the columns. We select 'movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', and 'crew'.
"""

movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]
print("\nDataFrame after filtering columns:")
print(movies.head())

"""## 5. Handling Missing Values

We check for and remove any rows with missing values in the selected columns to ensure data quality and prevent errors during subsequent processing.
"""

print("Number of missing values before dropping:")
print(movies.isnull().sum())
movies.dropna(inplace=True)
print("\nNumber of missing values after dropping:")
print(movies.isnull().sum())

"""## 6. Checking for Duplicates

We verify that there are no duplicate rows in the filtered DataFrame. Duplicate rows can skew the recommendation results.
"""

print("Number of duplicate rows:", movies.duplicated().sum())

"""## 7. Extracting Information from JSON Strings

Several columns ('genres', 'keywords', 'cast', and 'crew') contain data in JSON string format. We need to convert these strings into Python lists of dictionaries and extract the relevant information. For 'genres' and 'keywords', we extract the 'name'. For 'cast', we extract the 'name' of the first 3 cast members. For 'crew', we extract the 'name' of the director.
"""

movies['genres'] = movies['genres'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)])
movies['keywords'] = movies['keywords'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)])
movies['cast'] = movies['cast'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)][:3]) # Extracting only the first 3 cast members
movies['crew'] = movies['crew'].apply(lambda x: [i['name'] for i in ast.literal_eval(x) if i['job'] == 'Director']) # Extracting only the director's name

print("\nDataFrame after extracting information from JSON strings:")
print(movies.head())

"""## 8. Cleaning and Combining Tags

To create a unified representation for each movie, we clean the extracted lists by removing spaces from the elements and then combine the 'overview' (split into words), 'genres', 'keywords', 'cast', and 'crew' lists into a single 'tags' column.
"""

movies['overview'] = movies['overview'].apply(lambda x: x.split())
movies['genres'] = movies['genres'].apply(lambda x: [i.replace(' ', '') for i in x])
movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(' ', '') for i in x])
movies['cast'] = movies['cast'].apply(lambda x: [i.replace(' ', '') for i in x])
movies['crew'] = movies['crew'].apply(lambda x: [i.replace(' ', '') for i in x])

movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

print("\nDataFrame after cleaning and combining tags:")
print(movies.head())

"""## 9. Creating a New DataFrame with Essential Information

We create a new DataFrame `newdf` containing only the 'movie_id', 'title', and the newly created 'tags' column. This DataFrame will be used for vectorization and similarity calculation.
"""

newdf = movies[['movie_id', 'title', 'tags']]

print("\nNew DataFrame with essential information:")
print(newdf.head())

"""## 10. Lowercasing and Joining Tags

We convert the 'tags' column to lowercase and join the list of words/tags into a single string separated by spaces. This standardization is important for accurate text vectorization.
"""

newdf['tags'] = newdf['tags'].apply(lambda x: (" ".join(x)).lower())

print("\nDataFrame after lowercasing and joining tags:")
print(newdf.head())

"""## 11. Text Stemming

We apply stemming to the 'tags' column using the PorterStemmer from the NLTK library. Stemming reduces words to their root form, which helps in reducing the vocabulary size and improving the accuracy of the recommendation system by treating words with similar meanings as the same.
"""

import nltk
from nltk.stem.porter import PorterStemmer

ps = PorterStemmer()

def stem(text):
    y = []
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)

newdf['tags'] = newdf['tags'].apply(stem)

print("\nDataFrame after stemming tags:")
print(newdf.head())

"""## 12. Vectorizing Text Data

We use `CountVectorizer` from the scikit-learn library to convert the text data in the 'tags' column into a matrix of token counts. We limit the number of features to 5000 and remove English stop words to reduce noise and computational complexity.
"""

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(max_features=5000, stop_words='english')
vectors = cv.fit_transform(newdf['tags']).toarray()

print("\nShape of the vectors matrix:", vectors.shape)
print("\nTop 50 features:")
print(cv.get_feature_names_out()[:50])

"""## 13. Calculating Cosine Similarity

We calculate the cosine similarity between the movie vectors to determine the similarity between movies based on their tags. Cosine similarity measures the cosine of the angle between two non-zero vectors, providing a measure of their similarity.
"""

from sklearn.metrics.pairwise import cosine_similarity

similarity = cosine_similarity(vectors)

print("\nCosine similarity matrix:")
print(similarity.shape)

"""## 14. Creating a Recommendation Function

We define a Python function `recommend` that takes a movie title as input and returns the top 5 most similar movies based on the calculated cosine similarity. The function finds the index of the input movie, calculates the distance to all other movies using the similarity matrix, sorts the movies based on similarity, and returns the titles of the top 5 most similar movies (excluding the input movie itself).
"""

def recommend(movie):
    movie_index = newdf[newdf['title'] == movie].index[0]
    distance = similarity[movie_index]
    movie_list = sorted(list(enumerate(distance)), reverse=True, key=lambda x: x[1])[1:6]

    print(f"\nRecommendations for '{movie}':")
    for i in movie_list:
        print(newdf.iloc[i[0]].title)

"""## 15. Testing the Recommendation Function

Finally, we test the `recommend` function with an example movie title, "Avatar", to see the recommendations.
"""

recommend('Avatar')

import pickle

pickle.dump(newdf,open('movie_list.pkl','wb'))
pickle.dump(similarity,open('similarity.pkl','wb'))

pickle.dump(newdf.to_dict(), open('movie_dict.pkl', 'wb'))

